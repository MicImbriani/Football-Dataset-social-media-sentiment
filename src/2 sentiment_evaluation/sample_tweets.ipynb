{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Random Sampling for Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "MAX_SAMPLE_SIZE = 500\n",
    "N_ANNOTATION_ROUNDS = 2\n",
    "\n",
    "N_ANNOTATORS = 4\n",
    "TOTAL_N_INDIVIDUAL_SAMPLES = 100 * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Setup functionality for sampling tweets and querying the correct URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_url(tweet_id: str) -> str:\n",
    "    url = f'https://twitter.com/anyuser/status/{tweet_id}'\n",
    "    return f'<html><body><a href={url}>URL</a></body></html>'\n",
    "\n",
    "\n",
    "def sample_tweet(file_path: str, n_samples: int, random_state: int, filter_tweets=None) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file_path, sep=',', lineterminator='\\n')\n",
    "    df = df if filter_tweets is None else df[~df['tweet_id'].isin(\n",
    "        filter_tweets)]\n",
    "    df = df.sample(n=n_samples, random_state=random_state)\n",
    "    df = df.apply(lambda x: pd.Series({\n",
    "        'url': get_url(x.tweet_id),\n",
    "        'tweet_id': x.tweet_id,\n",
    "        'player_name': x.player_name}), axis=1)\n",
    "    df = df.astype({'url': str, 'tweet_id': 'int64', 'player_name': str})\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_group(df, N_splits, prefix):\n",
    "    frames = np.split(df, N_splits)\n",
    "    return pd.DataFrame({f'{prefix}_{i + 1}': frames[i].index for i in range(N_splits)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sample all overlapping player files and concat them into one DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = '../../data/collected_with_some_processing/tweets/all'\n",
    "PLAYER_FILES = list(map(lambda file: os.path.join(ROOT, file), os.listdir(ROOT)))\n",
    "OVERLAPPING_SAMPLES_PER_PLAYER = MAX_SAMPLE_SIZE // len(PLAYER_FILES)\n",
    "\n",
    "df_overlapping = pd.concat([sample_tweet(file, n_samples=OVERLAPPING_SAMPLES_PER_PLAYER, random_state=SEED) for file in PLAYER_FILES]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sample unique player files and concat them into one DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "UNIQUE_SAMPLES_PER_PLAYER = TOTAL_N_INDIVIDUAL_SAMPLES // len(PLAYER_FILES)\n",
    "df_unique = pd.concat([\n",
    "    sample_tweet(file, n_samples=UNIQUE_SAMPLES_PER_PLAYER,\n",
    "                 random_state=SEED, filter_tweets=df_overlapping['tweet_id'])\n",
    "    for file in PLAYER_FILES]).reset_index()\n",
    "assert not df_unique['tweet_id'].isin(df_overlapping['tweet_id']).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Split the overlapping data into the two groups used for the two rounds. We do that by grouping by the player and splitting each group into two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "groups = df_overlapping.groupby(by='player_name').apply(lambda df: split_group(df, N_splits=2, prefix='round'))\n",
    "group_1 = df_overlapping.iloc[groups['round_1'].values]\n",
    "group_2 = df_overlapping.iloc[groups['round_2'].values]\n",
    "\n",
    "# Assert grouping has done correctly.\n",
    "assert pd.DataFrame.all(group_1.groupby('player_name').index.count() == OVERLAPPING_SAMPLES_PER_PLAYER // N_ANNOTATION_ROUNDS)\n",
    "assert pd.DataFrame.all(group_2.groupby('player_name').index.count() == OVERLAPPING_SAMPLES_PER_PLAYER // N_ANNOTATION_ROUNDS)\n",
    "assert not group_1['tweet_id'].isin(group_2['tweet_id']).any()\n",
    "group_1_overlapping = group_1\n",
    "group_2_overlapping = group_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now split the unique data into 4 for each of the two rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "groups = df_unique.groupby(by='player_name').apply(lambda df: split_group(df, N_splits=2, prefix='round'))\n",
    "group_1 = df_unique.iloc[groups['round_1'].values]\n",
    "group_2 = df_unique.iloc[groups['round_2'].values]\n",
    "\n",
    "annotators_group_1 = group_1.groupby(by='player_name').apply(lambda df: split_group(df, N_splits=N_ANNOTATORS, prefix='annotator'))\n",
    "annotators_group_2 = group_2.groupby(by='player_name').apply(lambda df: split_group(df, N_splits=N_ANNOTATORS, prefix='annotator'))\n",
    "\n",
    "annotators_1 = [df_unique.iloc[annotators_group_1[f'annotator_{i + 1}'].values] for i in range(N_ANNOTATORS)]\n",
    "annotators_2 = [df_unique.iloc[annotators_group_2[f'annotator_{i + 1}'].values] for i in range(N_ANNOTATORS)]\n",
    "\n",
    "# Ensure no IDs are overlapping\n",
    "unique_ids = []\n",
    "for df in annotators_1 + annotators_2 + [group_1_overlapping] + [group_2_overlapping]:\n",
    "    for row in df.iterrows():\n",
    "        assert not row[1].tweet_id in unique_ids\n",
    "        unique_ids += [row[1].tweet_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Save the two annotation rounds for both overlapping and unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "group_1_overlapping.to_csv(f'round-1/samples_seed-{SEED}.csv', sep=',', index=None)\n",
    "group_2_overlapping.to_csv(f'round-2/samples_seed-{SEED}.csv', sep=',', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "initials = ['daen', 'miim', 'beke', 'toap']\n",
    "\n",
    "# Round 1\n",
    "for initial, df in zip(initials, annotators_1):\n",
    "    df.to_csv(f'round-1/{initial}/samples_seed-{SEED}.csv', sep=',', index=None)\n",
    "\n",
    "# Round 2\n",
    "for initial, df in zip(initials, annotators_2):\n",
    "    df.to_csv(f'round-2/{initial}/samples_seed-{SEED}.csv', sep=',', index=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dataWild')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8c0e2369a218edac00c595c539f0b28cb8865fad4fb946be064715462b040ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
